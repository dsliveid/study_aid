# 技术验证测试用例

## 目录

1. [测试概述](#1-测试概述)
2. [音频采集测试用例](#2-音频采集测试用例)
3. [音频处理测试用例](#3-音频处理测试用例)
4. [语音识别测试用例](#4-语音识别测试用例)
5. [集成测试用例](#5-集成测试用例)
6. [性能测试用例](#6-性能测试用例)

---

## 1. 测试概述

### 1.1 测试目标

**主要目标**：
- 验证音频采集功能的可行性与性能
- 验证音频处理算法的有效性
- 验证Faster-Whisper识别效果与性能
- 识别性能瓶颈
- 确定最终实现方案

### 1.2 测试环境

**硬件环境**：
- CPU：Intel Core i5 或更高
- 内存：8GB 或更高
- 硬盘：20GB 可用空间
- 音频设备：麦克风、扬声器

**软件环境**：
- 操作系统：Windows 10
- Python：3.8+
- 依赖库：见requirements.txt

### 1.3 测试工具

**测试框架**：
- unittest：Python单元测试框架
- pytest：高级测试框架
- time：性能测试

**测试数据**：
- 测试音频文件
- 噪声音频文件
- 中英混合音频文件

### 1.4 测试标准

**功能测试**：
- 功能正确性
- 边界条件
- 异常处理

**性能测试**：
- 响应时间
- 吞吐量
- 资源占用

**质量测试**：
- 音频质量
- 识别准确率
- 稳定性

---

## 2. 音频采集测试用例

### 2.1 设备枚举测试

#### TC-AC-001: 麦克风设备枚举

**测试目的**：验证能够正确枚举所有麦克风设备

**前置条件**：
- 系统已连接至少一个麦克风设备
- 已安装sounddevice库

**测试步骤**：
1. 运行设备枚举代码
2. 检查返回的设备列表
3. 验证每个设备的信息完整性

**测试代码**：
```python
import sounddevice as sd

def test_microphone_enumeration():
    """测试麦克风设备枚举"""
    devices = sd.query_devices()
    microphones = []

    for i, device in enumerate(devices):
        if device['max_input_channels'] > 0:
            microphones.append({
                'index': i,
                'name': device['name'],
                'channels': device['max_input_channels'],
                'sample_rate': device['default_samplerate']
            })

    assert len(microphones) > 0, "未找到麦克风设备"
    print(f"找到 {len(microphones)} 个麦克风设备")

    for mic in microphones:
        assert 'index' in mic, "设备缺少index字段"
        assert 'name' in mic, "设备缺少name字段"
        assert 'channels' in mic, "设备缺少channels字段"
        assert 'sample_rate' in mic, "设备缺少sample_rate字段"
        print(f"  设备 {mic['index']}: {mic['name']}")

    return True

if __name__ == "__main__":
    test_microphone_enumeration()
```

**预期结果**：
- 成功枚举所有麦克风设备
- 每个设备信息完整
- 设备索引正确

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

#### TC-AC-002: 系统音频设备枚举

**测试目的**：验证能够正确枚举所有系统音频输出设备

**前置条件**：
- 系统已连接至少一个音频输出设备
- 已安装sounddevice库

**测试步骤**：
1. 运行设备枚举代码
2. 检查返回的设备列表
3. 验证每个设备的信息完整性

**测试代码**：
```python
import sounddevice as sd

def test_system_audio_enumeration():
    """测试系统音频设备枚举"""
    devices = sd.query_devices()
    output_devices = []

    for i, device in enumerate(devices):
        if device['max_output_channels'] > 0:
            output_devices.append({
                'index': i,
                'name': device['name'],
                'channels': device['max_output_channels'],
                'sample_rate': device['default_samplerate']
            })

    assert len(output_devices) > 0, "未找到音频输出设备"
    print(f"找到 {len(output_devices)} 个音频输出设备")

    for dev in output_devices:
        assert 'index' in dev, "设备缺少index字段"
        assert 'name' in dev, "设备缺少name字段"
        assert 'channels' in dev, "设备缺少channels字段"
        assert 'sample_rate' in dev, "设备缺少sample_rate字段"
        print(f"  设备 {dev['index']}: {dev['name']}")

    return True

if __name__ == "__main__":
    test_system_audio_enumeration()
```

**预期结果**：
- 成功枚举所有音频输出设备
- 每个设备信息完整
- 设备索引正确

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

### 2.2 麦克风采集测试

#### TC-AC-003: 麦克风音频采集

**测试目的**：验证能够成功采集麦克风音频

**前置条件**：
- 系统已连接麦克风
- 已通过设备枚举测试

**测试步骤**：
1. 选择麦克风设备
2. 启动音频采集
3. 采集5秒音频
4. 验证音频数据完整性
5. 停止采集

**测试代码**：
```python
import sounddevice as sd
import numpy as np
import queue

def test_microphone_capture(device_index=None, duration=5):
    """测试麦克风音频采集"""
    audio_queue = queue.Queue(maxsize=100)

    def callback(indata, frames, time, status):
        if status:
            print(f"音频回调状态: {status}")
        audio_queue.put(indata.copy())

    # 创建音频流
    stream = sd.InputStream(
        device=device_index,
        channels=1,
        samplerate=16000,
        callback=callback
    )

    # 开始采集
    stream.start()
    print(f"开始采集麦克风音频 (设备: {device_index}, 时长: {duration}秒)")

    # 采集音频
    audio_chunks = []
    num_chunks = int(duration * 16000 / 1024)

    for i in range(num_chunks):
        audio_data = audio_queue.get(timeout=2.0)
        if audio_data is not None:
            audio_chunks.append(audio_data)
            print(f"  采集进度: {i+1}/{num_chunks}")

    # 停止采集
    stream.stop()
    stream.close()

    # 合并音频
    audio = np.concatenate(audio_chunks)

    # 验证音频
    assert len(audio) > 0, "未采集到音频数据"
    assert audio.dtype == np.float32, "音频数据类型不正确"
    print(f"采集完成，音频长度: {len(audio)} 采样点")
    print(f"音频时长: {len(audio) / 16000:.2f} 秒")

    return True

if __name__ == "__main__":
    test_microphone_capture(device_index=1, duration=5)
```

**预期结果**：
- 成功采集音频数据
- 音频数据类型正确
- 音频长度符合预期

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

#### TC-AC-004: 不同采样率采集

**测试目的**：验证不同采样率下的音频采集

**前置条件**：
- 系统已连接麦克风
- 已通过基础采集测试

**测试步骤**：
1. 测试8000 Hz采样率
2. 测试16000 Hz采样率
3. 测试44100 Hz采样率
4. 验证音频数据正确性

**测试代码**：
```python
import sounddevice as sd
import numpy as np
import queue

def test_different_sample_rates(device_index=None, duration=3):
    """测试不同采样率采集"""
    sample_rates = [8000, 16000, 44100]

    for sample_rate in sample_rates:
        print(f"\n测试采样率: {sample_rate} Hz")

        audio_queue = queue.Queue(maxsize=100)

        def callback(indata, frames, time, status):
            if status:
                print(f"音频回调状态: {status}")
            audio_queue.put(indata.copy())

        # 创建音频流
        stream = sd.InputStream(
            device=device_index,
            channels=1,
            samplerate=sample_rate,
            callback=callback
        )

        # 开始采集
        stream.start()

        # 采集音频
        audio_chunks = []
        num_chunks = int(duration * sample_rate / 1024)

        for i in range(num_chunks):
            audio_data = audio_queue.get(timeout=2.0)
            if audio_data is not None:
                audio_chunks.append(audio_data)

        # 停止采集
        stream.stop()
        stream.close()

        # 合并音频
        audio = np.concatenate(audio_chunks)

        # 验证音频
        assert len(audio) > 0, f"采样率 {sample_rate} Hz: 未采集到音频数据"
        expected_length = int(duration * sample_rate)
        assert abs(len(audio) - expected_length) < 100, f"采样率 {sample_rate} Hz: 音频长度不符合预期"
        print(f"  采样率 {sample_rate} Hz: 采集成功，音频长度: {len(audio)} 采样点")

    return True

if __name__ == "__main__":
    test_different_sample_rates(device_index=1, duration=3)
```

**预期结果**：
- 所有采样率都能成功采集
- 音频长度符合预期

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

### 2.3 系统音频采集测试

#### TC-AC-005: 系统音频Loopback采集

**测试目的**：验证能够成功采集系统音频

**前置条件**：
- 系统已连接音频输出设备
- 已通过设备枚举测试

**测试步骤**：
1. 选择音频输出设备
2. 播放测试音频
3. 启动Loopback采集
4. 采集5秒音频
5. 验证音频数据完整性

**测试代码**：
```python
import sounddevice as sd
import numpy as np
import queue

def test_system_audio_capture(device_index=None, duration=5):
    """测试系统音频Loopback采集"""
    audio_queue = queue.Queue(maxsize=100)

    def callback(indata, frames, time, status):
        if status:
            print(f"环回回调状态: {status}")
        audio_queue.put(indata.copy())

    # 创建音频流
    stream = sd.InputStream(
        device=device_index,
        channels=2,  # 系统音频通常是立体声
        samplerate=44100,
        callback=callback
    )

    # 开始采集
    stream.start()
    print(f"开始采集系统音频 (设备: {device_index}, 时长: {duration}秒)")
    print("请播放测试音频...")

    # 采集音频
    audio_chunks = []
    num_chunks = int(duration * 44100 / 1024)

    for i in range(num_chunks):
        audio_data = audio_queue.get(timeout=2.0)
        if audio_data is not None:
            audio_chunks.append(audio_data)
            print(f"  采集进度: {i+1}/{num_chunks}")

    # 停止采集
    stream.stop()
    stream.close()

    # 合并音频
    audio = np.concatenate(audio_chunks)

    # 验证音频
    assert len(audio) > 0, "未采集到音频数据"
    assert audio.shape[1] == 2, "系统音频应该是立体声"
    print(f"采集完成，音频长度: {len(audio)} 采样点")
    print(f"音频时长: {len(audio) / 44100:.2f} 秒")

    return True

if __name__ == "__main__":
    test_system_audio_capture(device_index=3, duration=5)
```

**预期结果**：
- 成功采集系统音频
- 音频为立体声
- 音频长度符合预期

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

### 2.4 音频源切换测试

#### TC-AC-006: 音频源切换

**测试目的**：验证能够在麦克风和系统音频之间切换

**前置条件**：
- 系统已连接麦克风和音频输出设备
- 已通过单独采集测试

**测试步骤**：
1. 启动麦克风采集
2. 采集3秒音频
3. 停止麦克风采集
4. 启动系统音频采集
5. 采集3秒音频
6. 停止系统音频采集
7. 验证两次采集都成功

**测试代码**：
```python
import sounddevice as sd
import numpy as np
import queue
import time

def test_audio_source_switch(mic_device_index=None, sys_device_index=None, duration=3):
    """测试音频源切换"""
    print("=== 测试音频源切换 ===\n")

    # 测试麦克风采集
    print("1. 启动麦克风采集")
    audio_queue = queue.Queue(maxsize=100)

    def callback(indata, frames, time, status):
        if status:
            print(f"音频回调状态: {status}")
        audio_queue.put(indata.copy())

    stream = sd.InputStream(
        device=mic_device_index,
        channels=1,
        samplerate=16000,
        callback=callback
    )

    stream.start()
    print(f"  正在采集麦克风音频...")

    audio_chunks = []
    num_chunks = int(duration * 16000 / 1024)

    for i in range(num_chunks):
        audio_data = audio_queue.get(timeout=2.0)
        if audio_data is not None:
            audio_chunks.append(audio_data)

    stream.stop()
    stream.close()

    mic_audio = np.concatenate(audio_chunks)
    print(f"  麦克风采集完成，长度: {len(mic_audio)} 采样点")

    # 等待1秒
    time.sleep(1)

    # 测试系统音频采集
    print("\n2. 启动系统音频采集")
    audio_queue = queue.Queue(maxsize=100)

    stream = sd.InputStream(
        device=sys_device_index,
        channels=2,
        samplerate=44100,
        callback=callback
    )

    stream.start()
    print(f"  正在采集系统音频...")

    audio_chunks = []
    num_chunks = int(duration * 44100 / 1024)

    for i in range(num_chunks):
        audio_data = audio_queue.get(timeout=2.0)
        if audio_data is not None:
            audio_chunks.append(audio_data)

    stream.stop()
    stream.close()

    sys_audio = np.concatenate(audio_chunks)
    print(f"  系统音频采集完成，长度: {len(sys_audio)} 采样点")

    # 验证
    assert len(mic_audio) > 0, "麦克风采集失败"
    assert len(sys_audio) > 0, "系统音频采集失败"
    print("\n音频源切换测试通过")

    return True

if __name__ == "__main__":
    test_audio_source_switch(mic_device_index=1, sys_device_index=3, duration=3)
```

**预期结果**：
- 麦克风采集成功
- 系统音频采集成功
- 切换过程无错误

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

### 2.5 长时间采集稳定性测试

#### TC-AC-007: 长时间采集稳定性

**测试目的**：验证长时间采集的稳定性

**前置条件**：
- 系统已连接麦克风
- 已通过基础采集测试

**测试步骤**：
1. 启动音频采集
2. 连续采集10分钟
3. 监控内存占用
4. 验证音频数据完整性
5. 停止采集

**测试代码**：
```python
import sounddevice as sd
import numpy as np
import queue
import time
import psutil

def test_long_time_capture(device_index=None, duration=600):
    """测试长时间采集稳定性"""
    print(f"=== 长时间采集测试 ({duration}秒) ===\n")

    audio_queue = queue.Queue(maxsize=100)

    def callback(indata, frames, time, status):
        if status:
            print(f"音频回调状态: {status}")
        audio_queue.put(indata.copy())

    # 创建音频流
    stream = sd.InputStream(
        device=device_index,
        channels=1,
        samplerate=16000,
        callback=callback
    )

    # 开始采集
    stream.start()
    print("开始长时间采集...")

    # 监控内存
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024

    # 采集音频
    audio_chunks = []
    start_time = time.time()
    chunk_count = 0

    while time.time() - start_time < duration:
        audio_data = audio_queue.get(timeout=2.0)
        if audio_data is not None:
            audio_chunks.append(audio_data)
            chunk_count += 1

            # 每100个chunk输出一次进度
            if chunk_count % 100 == 0:
                current_memory = process.memory_info().rss / 1024 / 1024
                elapsed = time.time() - start_time
                print(f"  进度: {elapsed:.1f}s / {duration}s, "
                      f"内存: {current_memory:.2f} MB, "
                      f"chunk数: {chunk_count}")

    # 停止采集
    stream.stop()
    stream.close()

    # 合并音频
    audio = np.concatenate(audio_chunks)

    # 验证
    final_memory = process.memory_info().rss / 1024 / 1024
    memory_increase = final_memory - initial_memory

    assert len(audio) > 0, "未采集到音频数据"
    print(f"\n采集完成:")
    print(f"  音频长度: {len(audio)} 采样点")
    print(f"  音频时长: {len(audio) / 16000:.2f} 秒")
    print(f"  初始内存: {initial_memory:.2f} MB")
    print(f"  最终内存: {final_memory:.2f} MB")
    print(f"  内存增加: {memory_increase:.2f} MB")

    # 检查内存泄漏
    assert memory_increase < 100, f"内存增加过多: {memory_increase:.2f} MB"

    return True

if __name__ == "__main__":
    test_long_time_capture(device_index=1, duration=600)
```

**预期结果**：
- 成功完成长时间采集
- 内存增加在合理范围内（< 100MB）
- 无崩溃或异常

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

## 3. 音频处理测试用例

### 3.1 格式转换测试

#### TC-AP-001: 采样率转换

**测试目的**：验证采样率转换的准确性

**前置条件**：
- 已安装scipy库

**测试步骤**：
1. 生成测试音频（44100 Hz）
2. 转换为16000 Hz
3. 验证转换后的音频长度
4. 验证音频数据类型

**测试代码**：
```python
import numpy as np
from scipy import signal

def test_sample_rate_conversion():
    """测试采样率转换"""
    print("=== 采样率转换测试 ===\n")

    # 生成测试音频
    original_rate = 44100
    target_rate = 16000
    duration = 5  # 秒

    audio_44k = np.random.randn(original_rate * duration).astype(np.float32)
    print(f"原始音频: {len(audio_44k)} 采样点 ({original_rate} Hz)")

    # 转换采样率
    number_of_samples = round(len(audio_44k) * float(target_rate) / original_rate)
    audio_16k = signal.resample(audio_44k, number_of_samples).astype(np.float32)

    print(f"转换后音频: {len(audio_16k)} 采样点 ({target_rate} Hz)")

    # 验证
    expected_length = int(duration * target_rate)
    assert abs(len(audio_16k) - expected_length) < 100, "音频长度不符合预期"
    assert audio_16k.dtype == np.float32, "音频数据类型不正确"

    # 计算转换误差
    error = np.mean(np.abs(audio_44k[::int(original_rate/target_rate)] - audio_16k))
    print(f"转换误差: {error:.6f}")

    print("\n采样率转换测试通过")
    return True

if __name__ == "__main__":
    test_sample_rate_conversion()
```

**预期结果**：
- 转换后的音频长度正确
- 音频数据类型正确
- 转换误差在合理范围内

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

#### TC-AP-002: 声道转换

**测试目的**：验证立体声转单声道的准确性

**前置条件**：
- 已安装numpy库

**测试步骤**：
1. 生成立体声测试音频
2. 转换为单声道
3. 验证转换后的音频
4. 测试不同转换方法

**测试代码**：
```python
import numpy as np

def test_channel_conversion():
    """测试声道转换"""
    print("=== 声道转换测试 ===\n")

    # 生成立体声测试音频
    duration = 5
    sample_rate = 16000
    stereo_audio = np.random.randn(sample_rate * duration, 2).astype(np.float32)
    print(f"立体声音频: {stereo_audio.shape}")

    # 测试平均法
    mono_avg = np.mean(stereo_audio, axis=1)
    print(f"平均法单声道: {mono_avg.shape}")

    # 测试左声道
    mono_left = stereo_audio[:, 0]
    print(f"左声道: {mono_left.shape}")

    # 测试右声道
    mono_right = stereo_audio[:, 1]
    print(f"右声道: {mono_right.shape}")

    # 验证
    assert len(mono_avg) == len(stereo_audio), "平均法转换失败"
    assert len(mono_left) == len(stereo_audio), "左声道转换失败"
    assert len(mono_right) == len(stereo_audio), "右声道转换失败"

    # 验证平均法结果
    expected_avg = (stereo_audio[:, 0] + stereo_audio[:, 1]) / 2
    assert np.allclose(mono_avg, expected_avg), "平均法计算错误"

    print("\n声道转换测试通过")
    return True

if __name__ == "__main__":
    test_channel_conversion()
```

**预期结果**：
- 所有转换方法都成功
- 转换后的音频长度正确
- 平均法计算正确

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

### 3.2 音频增强测试

#### TC-AP-003: 音量归一化

**测试目的**：验证音量归一化的效果

**前置条件**：
- 已安装numpy库

**测试步骤**：
1. 生成不同音量的测试音频
2. 应用峰值归一化
3. 验证归一化后的峰值
4. 应用RMS归一化
5. 验证归一化后的RMS

**测试代码**：
```python
import numpy as np

def test_volume_normalization():
    """测试音量归一化"""
    print("=== 音量归一化测试 ===\n")

    # 生成不同音量的测试音频
    audio_low = np.random.randn(16000).astype(np.float32) * 0.1
    audio_medium = np.random.randn(16000).astype(np.float32) * 0.5
    audio_high = np.random.randn(16000).astype(np.float32) * 0.9

    print("原始音频峰值:")
    print(f"  低音量: {np.max(np.abs(audio_low)):.4f}")
    print(f"  中音量: {np.max(np.abs(audio_medium)):.4f}")
    print(f"  高音量: {np.max(np.abs(audio_high)):.4f}")

    # 峰值归一化
    target_level = 0.95
    normalized_low = audio_low / np.max(np.abs(audio_low)) * target_level
    normalized_medium = audio_medium / np.max(np.abs(audio_medium)) * target_level
    normalized_high = audio_high / np.max(np.abs(audio_high)) * target_level

    print("\n峰值归一化后:")
    print(f"  低音量: {np.max(np.abs(normalized_low)):.4f}")
    print(f"  中音量: {np.max(np.abs(normalized_medium)):.4f}")
    print(f"  高音量: {np.max(np.abs(normalized_high)):.4f}")

    # 验证
    assert abs(np.max(np.abs(normalized_low)) - target_level) < 0.01, "低音量归一化失败"
    assert abs(np.max(np.abs(normalized_medium)) - target_level) < 0.01, "中音量归一化失败"
    assert abs(np.max(np.abs(normalized_high)) - target_level) < 0.01, "高音量归一化失败"

    # RMS归一化
    target_rms = 0.1
    rms_low = np.sqrt(np.mean(audio_low ** 2))
    rms_medium = np.sqrt(np.mean(audio_medium ** 2))
    rms_high = np.sqrt(np.mean(audio_high ** 2))

    normalized_rms_low = audio_low / rms_low * target_rms
    normalized_rms_medium = audio_medium / rms_medium * target_rms
    normalized_rms_high = audio_high / rms_high * target_rms

    print("\nRMS归一化后:")
    print(f"  低音量: {np.sqrt(np.mean(normalized_rms_low ** 2)):.4f}")
    print(f"  中音量: {np.sqrt(np.mean(normalized_rms_medium ** 2)):.4f}")
    print(f"  高音量: {np.sqrt(np.mean(normalized_rms_high ** 2)):.4f}")

    # 验证
    assert abs(np.sqrt(np.mean(normalized_rms_low ** 2)) - target_rms) < 0.01, "低音量RMS归一化失败"
    assert abs(np.sqrt(np.mean(normalized_rms_medium ** 2)) - target_rms) < 0.01, "中音量RMS归一化失败"
    assert abs(np.sqrt(np.mean(normalized_rms_high ** 2)) - target_rms) < 0.01, "高音量RMS归一化失败"

    print("\n音量归一化测试通过")
    return True

if __name__ == "__main__":
    test_volume_normalization()
```

**预期结果**：
- 峰值归一化后峰值接近目标值
- RMS归一化后RMS接近目标值
- 所有归一化都成功

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

#### TC-AP-004: 噪声抑制

**测试目的**：验证滤波器的噪声抑制效果

**前置条件**：
- 已安装scipy库

**测试步骤**：
1. 生成含噪声的测试音频
2. 应用高通滤波器
3. 应用低通滤波器
4. 应用带通滤波器
5. 验证滤波效果

**测试代码**：
```python
import numpy as np
from scipy import signal
from scipy.fft import fft, fftfreq

def test_noise_reduction():
    """测试噪声抑制"""
    print("=== 噪声抑制测试 ===\n")

    # 生成测试音频（包含低频和高频噪声）
    sample_rate = 16000
    duration = 5
    t = np.linspace(0, duration, sample_rate * duration)

    # 语音信号（300-3400 Hz）
    speech = np.sin(2 * np.pi * 1000 * t)

    # 低频噪声（50 Hz）
    low_noise = 0.3 * np.sin(2 * np.pi * 50 * t)

    # 高频噪声（8000 Hz）
    high_noise = 0.2 * np.sin(2 * np.pi * 8000 * t)

    # 混合信号
    noisy_audio = speech + low_noise + high_noise

    print(f"原始音频:")
    print(f"  RMS: {np.sqrt(np.mean(noisy_audio ** 2)):.4f}")

    # 高通滤波器（去除低频噪声）
    nyquist = 0.5 * sample_rate
    normal_cutoff = 80 / nyquist
    b, a = signal.butter(5, normal_cutoff, btype='high', analog=False)
    highpass_audio = signal.filtfilt(b, a, noisy_audio)

    print(f"高通滤波后:")
    print(f"  RMS: {np.sqrt(np.mean(highpass_audio ** 2)):.4f}")

    # 低通滤波器（去除高频噪声）
    normal_cutoff = 8000 / nyquist
    b, a = signal.butter(5, normal_cutoff, btype='low', analog=False)
    lowpass_audio = signal.filtfilt(b, a, highpass_audio)

    print(f"低通滤波后:")
    print(f"  RMS: {np.sqrt(np.mean(lowpass_audio ** 2)):.4f}")

    # 带通滤波器（300-3400 Hz）
    low = 300 / nyquist
    high = 3400 / nyquist
    b, a = signal.butter(5, [low, high], btype='band', analog=False)
    bandpass_audio = signal.filtfilt(b, a, noisy_audio)

    print(f"带通滤波后:")
    print(f"  RMS: {np.sqrt(np.mean(bandpass_audio ** 2)):.4f}")

    # 验证滤波效果
    assert np.sqrt(np.mean(highpass_audio ** 2)) < np.sqrt(np.mean(noisy_audio ** 2)), "高通滤波失败"
    assert np.sqrt(np.mean(lowpass_audio ** 2)) < np.sqrt(np.mean(highpass_audio ** 2)), "低通滤波失败"

    print("\n噪声抑制测试通过")
    return True

if __name__ == "__main__":
    test_noise_reduction()
```

**预期结果**：
- 滤波器成功应用
- 滤波后RMS降低
- 滤波效果明显

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

### 3.3 VAD测试

#### TC-AP-005: 能量阈值VAD

**测试目的**：验证基于能量的VAD功能

**前置条件**：
- 已安装numpy库

**测试步骤**：
1. 生成包含语音和静音的测试音频
2. 应用能量阈值VAD
3. 验证检测结果

**测试代码**：
```python
import numpy as np

def test_energy_vad():
    """测试能量阈值VAD"""
    print("=== 能量阈值VAD测试 ===\n")

    # 生成测试音频（包含语音和静音）
    sample_rate = 16000
    silence_duration = 2  # 秒
    speech_duration = 2  # 秒

    # 静音
    silence = np.random.randn(sample_rate * silence_duration).astype(np.float32) * 0.01

    # 语音
    speech = np.random.randn(sample_rate * speech_duration).astype(np.float32) * 0.5

    # 混合
    audio = np.concatenate([silence, speech, silence])

    print(f"音频总时长: {len(audio) / sample_rate:.2f} 秒")
    print(f"静音段1: 0-{silence_duration}秒")
    print(f"语音段: {silence_duration}-{silence_duration+speech_duration}秒")
    print(f"静音段2: {silence_duration+speech_duration}-{silence_duration*2+speech_duration}秒")

    # VAD检测
    frame_length = 1024
    frame_shift = 512
    energy_threshold = 0.01

    num_frames = 1 + (len(audio) - frame_length) // frame_shift
    speech_flags = []

    for i in range(num_frames):
        start = i * frame_shift
        end = start + frame_length
        frame = audio[start:end]

        if len(frame) < frame_length:
            break

        energy = np.mean(frame ** 2)
        speech_flags.append(energy > energy_threshold)

    print(f"\n检测到 {sum(speech_flags)} 个语音帧 / {len(speech_flags)} 总帧数")
    print(f"语音比例: {sum(speech_flags) / len(speech_flags):.2%}")

    # 验证
    assert sum(speech_flags) > 0, "未检测到语音"
    assert sum(speech_flags) < len(speech_flags), "所有帧都被检测为语音"

    print("\n能量阈值VAD测试通过")
    return True

if __name__ == "__main__":
    test_energy_vad()
```

**预期结果**：
- 成功检测到语音段
- 语音段比例合理
- 静音段被正确识别

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

## 4. 语音识别测试用例

### 4.1 模型加载测试

#### TC-SR-001: 模型初始化

**测试目的**：验证Faster-Whisper模型能够成功初始化

**前置条件**：
- 已安装faster-whisper库
- 模型文件已下载

**测试步骤**：
1. 加载tiny模型
2. 验证模型加载成功
3. 测试不同模型大小

**测试代码**：
```python
from faster_whisper import WhisperModel

def test_model_initialization():
    """测试模型初始化"""
    print("=== 模型初始化测试 ===\n")

    model_sizes = ["tiny", "base"]

    for model_size in model_sizes:
        print(f"加载模型: {model_size}")

        try:
            model = WhisperModel(
                model_size,
                device="cpu",
                compute_type="int8"
            )
            print(f"  模型 {model_size} 加载成功")

            # 验证模型
            assert model is not None, f"模型 {model_size} 加载失败"

        except Exception as e:
            print(f"  模型 {model_size} 加载失败: {e}")
            raise

    print("\n模型初始化测试通过")
    return True

if __name__ == "__main__":
    test_model_initialization()
```

**预期结果**：
- 所有模型都能成功加载
- 模型对象不为空

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

### 4.2 识别功能测试

#### TC-SR-002: 中文识别

**测试目的**：验证中文语音识别功能

**前置条件**：
- 已通过模型初始化测试
- 准备中文测试音频

**测试步骤**：
1. 加载模型
2. 识别中文测试音频
3. 验证识别结果
4. 检查识别准确率

**测试代码**：
```python
from faster_whisper import WhisperModel
import numpy as np

def test_chinese_recognition(audio_file=None):
    """测试中文识别"""
    print("=== 中文识别测试 ===\n")

    # 加载模型
    model = WhisperModel("base", device="cpu", compute_type="int8")
    print("模型加载成功")

    # 如果没有提供音频文件，生成测试音频
    if audio_file is None:
        print("生成测试音频...")
        sample_rate = 16000
        duration = 5
        audio = np.random.randn(sample_rate * duration).astype(np.float32) * 0.5
        print("测试音频生成完成")
    else:
        from scipy.io import wavfile
        sample_rate, audio = wavfile.read(audio_file)
        audio = audio.astype(np.float32) / 32767.0

    # 识别
    print("开始识别...")
    segments, info = model.transcribe(
        audio,
        language="zh",
        beam_size=5,
        vad_filter=True
    )

    # 输出结果
    print(f"\n检测到的语言: {info.language} (概率: {info.language_probability:.2f})")
    print("\n识别结果:")

    results = []
    for segment in segments:
        print(f"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")
        results.append({
            'text': segment.text,
            'start': segment.start,
            'end': segment.end
        })

    # 验证
    assert len(results) > 0, "未识别到任何文本"

    print(f"\n识别到 {len(results)} 个片段")
    print("中文识别测试通过")

    return results

if __name__ == "__main__":
    test_chinese_recognition()
```

**预期结果**：
- 成功识别中文语音
- 识别结果不为空
- 语言识别正确

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

#### TC-SR-003: 英文识别

**测试目的**：验证英文语音识别功能

**前置条件**：
- 已通过模型初始化测试
- 准备英文测试音频

**测试步骤**：
1. 加载模型
2. 识别英文测试音频
3. 验证识别结果
4. 检查识别准确率

**测试代码**：
```python
from faster_whisper import WhisperModel
import numpy as np

def test_english_recognition(audio_file=None):
    """测试英文识别"""
    print("=== 英文识别测试 ===\n")

    # 加载模型
    model = WhisperModel("base", device="cpu", compute_type="int8")
    print("模型加载成功")

    # 如果没有提供音频文件，生成测试音频
    if audio_file is None:
        print("生成测试音频...")
        sample_rate = 16000
        duration = 5
        audio = np.random.randn(sample_rate * duration).astype(np.float32) * 0.5
        print("测试音频生成完成")
    else:
        from scipy.io import wavfile
        sample_rate, audio = wavfile.read(audio_file)
        audio = audio.astype(np.float32) / 32767.0

    # 识别
    print("开始识别...")
    segments, info = model.transcribe(
        audio,
        language="en",
        beam_size=5,
        vad_filter=True
    )

    # 输出结果
    print(f"\n检测到的语言: {info.language} (概率: {info.language_probability:.2f})")
    print("\n识别结果:")

    results = []
    for segment in segments:
        print(f"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")
        results.append({
            'text': segment.text,
            'start': segment.start,
            'end': segment.end
        })

    # 验证
    assert len(results) > 0, "未识别到任何文本"

    print(f"\n识别到 {len(results)} 个片段")
    print("英文识别测试通过")

    return results

if __name__ == "__main__":
    test_english_recognition()
```

**预期结果**：
- 成功识别英文语音
- 识别结果不为空
- 语言识别正确

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

#### TC-SR-004: 中英混合识别

**测试目的**：验证中英混合语音识别功能

**前置条件**：
- 已通过单独语言识别测试
- 准备中英混合测试音频

**测试步骤**：
1. 加载模型
2. 识别中英混合测试音频
3. 验证识别结果
4. 检查语言切换

**测试代码**：
```python
from faster_whisper import WhisperModel
import numpy as np

def test_mixed_language_recognition(audio_file=None):
    """测试中英混合识别"""
    print("=== 中英混合识别测试 ===\n")

    # 加载模型
    model = WhisperModel("base", device="cpu", compute_type="int8")
    print("模型加载成功")

    # 如果没有提供音频文件，生成测试音频
    if audio_file is None:
        print("生成测试音频...")
        sample_rate = 16000
        duration = 10
        audio = np.random.randn(sample_rate * duration).astype(np.float32) * 0.5
        print("测试音频生成完成")
    else:
        from scipy.io import wavfile
        sample_rate, audio = wavfile.read(audio_file)
        audio = audio.astype(np.float32) / 32767.0

    # 识别（不指定语言，让模型自动识别）
    print("开始识别...")
    segments, info = model.transcribe(
        audio,
        beam_size=5,
        vad_filter=True
    )

    # 输出结果
    print(f"\n检测到的语言: {info.language} (概率: {info.language_probability:.2f})")
    print("\n识别结果:")

    results = []
    for segment in segments:
        print(f"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")
        results.append({
            'text': segment.text,
            'start': segment.start,
            'end': segment.end
        })

    # 验证
    assert len(results) > 0, "未识别到任何文本"

    print(f"\n识别到 {len(results)} 个片段")
    print("中英混合识别测试通过")

    return results

if __name__ == "__main__":
    test_mixed_language_recognition()
```

**预期结果**：
- 成功识别中英混合语音
- 识别结果不为空
- 语言切换正确

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

### 4.3 实时识别测试

#### TC-SR-005: 流式识别

**测试目的**：验证流式识别功能

**前置条件**：
- 已通过基础识别测试
- 准备长音频文件

**测试步骤**：
1. 加载模型
2. 分块处理音频
3. 实时输出识别结果
4. 验证流式识别效果

**测试代码**：
```python
from faster_whisper import WhisperModel
import numpy as np
import time

def test_streaming_recognition(audio_file=None, chunk_duration=3):
    """测试流式识别"""
    print("=== 流式识别测试 ===\n")

    # 加载模型
    model = WhisperModel("base", device="cpu", compute_type="int8")
    print("模型加载成功")

    # 如果没有提供音频文件，生成测试音频
    if audio_file is None:
        print("生成测试音频...")
        sample_rate = 16000
        duration = 15
        audio = np.random.randn(sample_rate * duration).astype(np.float32) * 0.5
        print("测试音频生成完成")
    else:
        from scipy.io import wavfile
        sample_rate, audio = wavfile.read(audio_file)
        audio = audio.astype(np.float32) / 32767.0

    # 流式识别
    chunk_size = int(chunk_duration * sample_rate)
    num_chunks = len(audio) // chunk_size

    print(f"\n开始流式识别 (chunk时长: {chunk_duration}秒, 总chunk数: {num_chunks})")

    all_results = []
    for i in range(num_chunks):
        start_time = time.time()

        chunk = audio[i * chunk_size:(i + 1) * chunk_size]

        segments, _ = model.transcribe(
            chunk,
            language="zh",
            beam_size=5,
            vad_filter=True
        )

        chunk_results = []
        for segment in segments:
            chunk_results.append({
                'text': segment.text,
                'start': segment.start,
                'end': segment.end
            })
            print(f"Chunk {i+1}/{num_chunks}: {segment.text}")

        all_results.extend(chunk_results)

        elapsed = time.time() - start_time
        print(f"  处理时间: {elapsed:.2f}s")

    # 验证
    print(f"\n流式识别完成，共识别到 {len(all_results)} 个片段")
    print("流式识别测试通过")

    return all_results

if __name__ == "__main__":
    test_streaming_recognition()
```

**预期结果**：
- 成功完成流式识别
- 每个chunk都有识别结果
- 处理时间合理

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

## 5. 集成测试用例

### 5.1 端到端测试

#### TC-INT-001: 完整流程测试

**测试目的**：验证从音频采集到识别的完整流程

**前置条件**：
- 已通过所有单独模块测试

**测试步骤**：
1. 采集麦克风音频
2. 处理音频
3. 识别音频
4. 输出结果

**测试代码**：
```python
import sounddevice as sd
import numpy as np
import queue
from faster_whisper import WhisperModel
from scipy import signal

def test_end_to_end(device_index=None, duration=5):
    """测试端到端流程"""
    print("=== 端到端流程测试 ===\n")

    # 步骤1: 音频采集
    print("步骤1: 音频采集")
    audio_queue = queue.Queue(maxsize=100)

    def callback(indata, frames, time, status):
        if status:
            print(f"音频回调状态: {status}")
        audio_queue.put(indata.copy())

    stream = sd.InputStream(
        device=device_index,
        channels=1,
        samplerate=16000,
        callback=callback
    )

    stream.start()
    print(f"  开始采集音频 (时长: {duration}秒)")

    audio_chunks = []
    num_chunks = int(duration * 16000 / 1024)

    for i in range(num_chunks):
        audio_data = audio_queue.get(timeout=2.0)
        if audio_data is not None:
            audio_chunks.append(audio_data)

    stream.stop()
    stream.close()

    audio = np.concatenate(audio_chunks)
    print(f"  采集完成，音频长度: {len(audio)} 采样点")

    # 步骤2: 音频处理
    print("\n步骤2: 音频处理")
    audio = signal.resample(audio, len(audio)).astype(np.float32)
    max_val = np.max(np.abs(audio))
    if max_val > 0:
        audio = audio / max_val * 0.95
    print(f"  处理完成，峰值: {np.max(np.abs(audio)):.4f}")

    # 步骤3: 语音识别
    print("\n步骤3: 语音识别")
    model = WhisperModel("base", device="cpu", compute_type="int8")

    segments, info = model.transcribe(
        audio,
        language="zh",
        beam_size=5,
        vad_filter=True
    )

    print(f"  检测到的语言: {info.language} (概率: {info.language_probability:.2f})")

    # 步骤4: 输出结果
    print("\n步骤4: 识别结果")
    results = []
    for segment in segments:
        print(f"  [{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")
        results.append({
            'text': segment.text,
            'start': segment.start,
            'end': segment.end
        })

    # 验证
    assert len(audio) > 0, "音频采集失败"
    assert len(results) > 0, "语音识别失败"

    print(f"\n端到端测试完成，识别到 {len(results)} 个片段")
    print("端到端流程测试通过")

    return results

if __name__ == "__main__":
    test_end_to_end(device_index=1, duration=5)
```

**预期结果**：
- 所有步骤都成功执行
- 最终有识别结果
- 流程无错误

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

## 6. 性能测试用例

### 6.1 响应时间测试

#### TC-PERF-001: 识别延迟测试

**测试目的**：测量语音识别的延迟

**前置条件**：
- 已通过功能测试

**测试步骤**：
1. 准备测试音频
2. 测量识别时间
3. 计算延迟
4. 评估性能

**测试代码**：
```python
from faster_whisper import WhisperModel
import numpy as np
import time

def test_recognition_latency(audio_file=None, num_runs=5):
    """测试识别延迟"""
    print("=== 识别延迟测试 ===\n")

    # 加载模型
    model = WhisperModel("base", device="cpu", compute_type="int8")
    print("模型加载成功")

    # 如果没有提供音频文件，生成测试音频
    if audio_file is None:
        print("生成测试音频...")
        sample_rate = 16000
        duration = 5
        audio = np.random.randn(sample_rate * duration).astype(np.float32) * 0.5
        print("测试音频生成完成")
    else:
        from scipy.io import wavfile
        sample_rate, audio = wavfile.read(audio_file)
        audio = audio.astype(np.float32) / 32767.0

    # 多次测试
    latencies = []
    print(f"\n开始测试 (运行次数: {num_runs})")

    for i in range(num_runs):
        start_time = time.time()

        segments, _ = model.transcribe(
            audio,
            language="zh",
            beam_size=5,
            vad_filter=True
        )

        # 消耗所有segment
        results = list(segments)

        end_time = time.time()
        latency = end_time - start_time
        latencies.append(latency)

        print(f"  运行 {i+1}/{num_runs}: {latency:.2f}s")

    # 计算统计信息
    avg_latency = np.mean(latencies)
    min_latency = np.min(latencies)
    max_latency = np.max(latencies)
    std_latency = np.std(latencies)

    print(f"\n延迟统计:")
    print(f"  平均延迟: {avg_latency:.2f}s")
    print(f"  最小延迟: {min_latency:.2f}s")
    print(f"  最大延迟: {max_latency:.2f}s")
    print(f"  标准差: {std_latency:.2f}s")

    # 验证
    assert avg_latency < 10.0, f"平均延迟过高: {avg_latency:.2f}s"

    print("\n识别延迟测试通过")
    return latencies

if __name__ == "__main__":
    test_recognition_latency(num_runs=5)
```

**预期结果**：
- 平均延迟 < 10秒
- 延迟波动较小
- 性能稳定

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

### 6.2 资源占用测试

#### TC-PERF-002: CPU和内存占用测试

**测试目的**：测量识别过程中的CPU和内存占用

**前置条件**：
- 已通过功能测试
- 已安装psutil库

**测试步骤**：
1. 监控初始资源占用
2. 执行识别任务
3. 监控峰值资源占用
4. 分析资源使用情况

**测试代码**：
```python
from faster_whisper import WhisperModel
import numpy as np
import psutil
import time

def test_resource_usage(audio_file=None):
    """测试资源占用"""
    print("=== 资源占用测试 ===\n")

    # 加载模型
    print("加载模型...")
    model = WhisperModel("base", device="cpu", compute_type="int8")
    print("模型加载成功")

    # 如果没有提供音频文件，生成测试音频
    if audio_file is None:
        print("生成测试音频...")
        sample_rate = 16000
        duration = 5
        audio = np.random.randn(sample_rate * duration).astype(np.float32) * 0.5
        print("测试音频生成完成")
    else:
        from scipy.io import wavfile
        sample_rate, audio = wavfile.read(audio_file)
        audio = audio.astype(np.float32) / 32767.0

    # 获取当前进程
    process = psutil.Process()

    # 监控资源
    print("\n开始监控资源...")

    # 初始资源
    initial_cpu = process.cpu_percent(interval=1.0)
    initial_memory = process.memory_info().rss / 1024 / 1024

    print(f"初始资源:")
    print(f"  CPU: {initial_cpu:.1f}%")
    print(f"  内存: {initial_memory:.2f} MB")

    # 执行识别
    print("\n开始识别...")
    start_time = time.time()

    segments, _ = model.transcribe(
        audio,
        language="zh",
        beam_size=5,
        vad_filter=True
    )

    # 消耗所有segment
    results = list(segments)

    end_time = time.time()

    # 峰值资源
    peak_cpu = process.cpu_percent(interval=0.1)
    peak_memory = process.memory_info().rss / 1024 / 1024

    print(f"\n峰值资源:")
    print(f"  CPU: {peak_cpu:.1f}%")
    print(f"  内存: {peak_memory:.2f} MB")

    # 资源变化
    cpu_increase = peak_cpu - initial_cpu
    memory_increase = peak_memory - initial_memory

    print(f"\n资源变化:")
    print(f"  CPU增加: {cpu_increase:.1f}%")
    print(f"  内存增加: {memory_increase:.2f} MB")

    # 识别时间
    recognition_time = end_time - start_time
    print(f"\n识别时间: {recognition_time:.2f}s")

    # 验证
    assert peak_memory < 2000, f"内存占用过高: {peak_memory:.2f} MB"
    assert peak_cpu < 100, f"CPU占用过高: {peak_cpu:.1f}%"

    print("\n资源占用测试通过")
    return {
        'initial_cpu': initial_cpu,
        'peak_cpu': peak_cpu,
        'initial_memory': initial_memory,
        'peak_memory': peak_memory,
        'recognition_time': recognition_time
    }

if __name__ == "__main__":
    test_resource_usage()
```

**预期结果**：
- 峰值内存 < 2000MB
- 峰值CPU < 100%
- 资源占用合理

**实际结果**：____________________

**测试状态**：□ 通过 □ 失败

---

## 测试总结

### 测试结果汇总

| 模块 | 测试用例数 | 通过 | 失败 | 通过率 |
|------|-----------|------|------|--------|
| 音频采集 | 7 | ___ | ___ | ___% |
| 音频处理 | 5 | ___ | ___ | ___% |
| 语音识别 | 5 | ___ | ___ | ___% |
| 集成测试 | 1 | ___ | ___ | ___% |
| 性能测试 | 2 | ___ | ___ | ___% |
| **总计** | **20** | **___** | **___** | **___%** |

### 性能指标

| 指标 | 目标值 | 实际值 | 状态 |
|------|--------|--------|------|
| 识别延迟 | < 10s | ___ | ___ |
| 峰值内存 | < 2000MB | ___ | ___ |
| 峰值CPU | < 100% | ___ | ___ |
| 识别准确率 | > 90% | ___ | ___ |

### 问题与建议

**发现的问题**：
1. ____________________
2. ____________________
3. ____________________

**优化建议**：
1. ____________________
2. ____________________
3. ____________________

---

**文档版本**：v1.0  
**创建日期**：2024-01-01  
**最后更新**：2024-01-01
